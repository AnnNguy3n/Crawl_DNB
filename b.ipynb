{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CONFIG import FOLDER_DATA\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path(p: str):\n",
    "    try:\n",
    "        re.search(r\"\\d+\\_\\d+\\.\\d+\\.csv\", p).group()\n",
    "        return True\n",
    "    except: return False\n",
    "\n",
    "list_path = [f\"{FOLDER_DATA}/Raw_Data/\" + p for p in os.listdir(f\"{FOLDER_DATA}/Raw_Data\") if check_path(p)]\n",
    "# list_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(text_: str, *args):\n",
    "    text = text_\n",
    "    try:\n",
    "        for arg in args:\n",
    "            text = text.replace(arg, \" \")\n",
    "\n",
    "        return text.replace(\"\\xa0\", \" \").replace(\"\\n\", \" \").strip()\n",
    "    except: return text_\n",
    "\n",
    "def tf_key_principal(text: str):\n",
    "    return transform(text, \"Key Principal:\", \"See more contacts\")\n",
    "\n",
    "def tf_address(text: str):\n",
    "    return transform(text, \"Address:\", \"See other locations\")\n",
    "\n",
    "def tf_website(text: str):\n",
    "    return transform(text, \"Website:\")\n",
    "\n",
    "def tf_revenue(text: str):\n",
    "    text = transform(text, \"Revenue:\")\n",
    "    try:\n",
    "        temp_lst = text.split(\" \")\n",
    "        return \" &&& \".join([p for p in temp_lst if p != \"\"])\n",
    "    except: return text\n",
    "\n",
    "def tf_industry(text_: str):\n",
    "    text = text_\n",
    "    try:\n",
    "        temp_lst = text.replace(\"Industry:\", \" \").replace(\"See All Industries\", \",\\xa0\").replace(\"See Fewer Industries\", \" \").replace(\"\\n\", \" \").split(\",\\xa0\")\n",
    "        lst = [p.strip() for p in temp_lst]\n",
    "        return \" &&& \".join(lst)\n",
    "    except: return text_\n",
    "\n",
    "def tf_contacts(text: str):\n",
    "    return transform(text, \"ContactsReach the right people with access to detailed contact information.\")\n",
    "\n",
    "def tf_contact(text_: str):\n",
    "    text = text_\n",
    "    try:\n",
    "        temp_lst = [p for p in text.split(\"\\n\") if p != \"\"]\n",
    "        return \" &&& \".join(temp_lst)\n",
    "    except: return text_\n",
    "\n",
    "def transform_data(data):\n",
    "    data[\"key_principal\"] = data[\"key_principal\"].apply(tf_key_principal)\n",
    "    data[\"address\"] = data[\"address\"].apply(tf_address)\n",
    "    data[\"website\"] = data[\"website\"].apply(tf_website)\n",
    "    data[\"industry\"] = data[\"industry\"].apply(tf_industry)\n",
    "    data[\"contact_1\"] = data[\"contact_1\"].apply(tf_contact)\n",
    "    data[\"contact_2\"] = data[\"contact_2\"].apply(tf_contact)\n",
    "    data[\"contact_3\"] = data[\"contact_3\"].apply(tf_contact)\n",
    "    data[\"contact_4\"] = data[\"contact_4\"].apply(tf_contact)\n",
    "    data[\"revenue\"] = data[\"revenue\"].apply(tf_revenue)\n",
    "    data[\"contacts\"] = data[\"contacts\"].apply(tf_contacts)\n",
    "    data.loc[data[\"contact_1\"] == \"Contact 1\", \"contact_1\"] = pd.NA\n",
    "    data.loc[data[\"contact_2\"] == \"Contact 2\", \"contact_2\"] = pd.NA\n",
    "    data.loc[data[\"contact_3\"] == \"Contact 3\", \"contact_3\"] = pd.NA\n",
    "    data.loc[data[\"contact_4\"] == \"Contact 4\", \"contact_4\"] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/home/nguyen/huuann.nnguyen199012_drive/Data_DNB/Data_F1\", exist_ok=True)\n",
    "for i in range(len(list_path)):\n",
    "    path_save = list_path[i].replace(\"Raw_Data\", \"Data_F1\")\n",
    "    if not os.path.exists(path_save):\n",
    "        print(i)\n",
    "        data = pd.read_csv(list_path[i])\n",
    "        transform_data(data)\n",
    "        print(path_save)\n",
    "        data.to_csv(path_save, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CONFIG import FOLDER_DATA\n",
    "import os\n",
    "import pandas as pd\n",
    "len(os.listdir(f\"{FOLDER_DATA}/Data_F1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_path = [f\"{FOLDER_DATA}/Data_F1/\"+p for p in os.listdir(f\"{FOLDER_DATA}/Data_F1\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = []\n",
    "k = 0\n",
    "for path in list_path:\n",
    "    list_data.append(pd.read_csv(path))\n",
    "    print(k)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat(list_data, ignore_index=True)\n",
    "len(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full[full[\"address\"].notna()].reset_index(drop=True)\n",
    "len(full)\n",
    "# texas = temp[(~temp[\"address\"].str.contains(\", FL,\")) & (~temp[\"address\"].str.contains(\", TX,\"))]\n",
    "# texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texas = full[~(full[\"address\"].str.contains(\", FL\")) & ~(full[\"address\"].str.contains(\", TX\"))].copy().reset_index(drop=True)\n",
    "# texas = full[full[\"address\"].str.contains(\", TX\")]\n",
    "texas.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find(text):\n",
    "    try: return re.search(r\"\\w+, FL\", text).group()\n",
    "    except: return \"notFound\"\n",
    "\n",
    "texas[\"address\"].apply(find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texas[\"temp\"] = texas[\"address\"].apply(find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texas.sort_values([\"temp\", \"industry\", \"name_company\", \"website\"], ignore_index=True, inplace=True)\n",
    "texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texas.to_csv(\"test.csv\")\n",
    "# texas.pop(\"temp\")\n",
    "1384110 + 1476782 + 6711 - len(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/home/nguyen/huuann.nnguyen199012_drive/Data_DNB/Final_Data', exist_ok=True)\n",
    "texas.to_csv('/home/nguyen/huuann.nnguyen199012_drive/Data_DNB/Final_Data/florida.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.read_csv(\"/home/nguyen/huuann.nnguyen199012_drive/Data_DNB/Final_Data/florida.csv\"))\\\n",
    "+len(pd.read_csv(\"/home/nguyen/huuann.nnguyen199012_drive/Data_DNB/Final_Data/texas.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full) - 2860877"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
